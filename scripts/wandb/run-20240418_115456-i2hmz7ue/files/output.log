/home/yash/Desktop/Biorobotics_Lab/moving_mass_RL-master/scripts/ppo.py:249: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  obs, act, adv, logp_old = torch.tensor(data['obs'],dtype=torch.float,device='cuda:0'),torch.tensor(data['act'],dtype=torch.float,device='cuda:0'), torch.tensor(data['adv'],dtype=torch.float,device='cuda:0'), torch.tensor(data['logp'],dtype=torch.float,device='cuda:0')
/home/yash/Desktop/Biorobotics_Lab/moving_mass_RL-master/scripts/ppo.py:269: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  obs, ret = torch.tensor(data['obs'],dtype=torch.float,device='cuda:0'), torch.tensor(data['ret'],dtype=torch.float,device='cuda:0')
0 873.1113272123209 0.092 -17.742 0.0 tensor(-1.6618)
1 950.6391425440848 0.02 -16.808 0.0 tensor(-1.3156)
2 756.9878983016115 0.517 -15.686 -0.004 tensor(-3.3197)
3 799.2664223498592 0.073 -16.587 -0.004 tensor(-0.8171)
4 957.6355126071551 0.196 -39.656 -0.001 tensor(-0.9777)
5 848.8922357525931 0.112 -36.926 -0.004 tensor(-0.9714)

6 990.7311945631121 0.29 -42.94 -0.006 tensor(0.7765)
7 678.533544484462 0.066 -44.879 -0.003 tensor(-0.3569)
8 611.7000785437624 0.439 -35.189 -0.004 tensor(0.1258)
9 1108.9859690467883 0.483 -73.947 -0.012 tensor(0.7726)
10 204.0803268165556 0.124 -79.416 -0.012 tensor(-1.0610)
11 602.3670921155391 0.506 -20.912 -0.015 tensor(-1.9436)
12 427.02524190913664 0.717 -0.323 -0.01 tensor(-1.3489)
13 1047.1361566053151 0.238 -77.388 -0.01 tensor(-1.4776)
14 1336.0634738560684 0.15 -187.832 -0.007 tensor(-3.7594)
15 549.324643184373 0.681 -5.983 -0.011 tensor(-2.6184)
16 1235.129451903848 0.629 -95.104 -0.004 tensor(0.9289)
17 107.6176532515492 0.022 -8.022 -0.01 tensor(-0.9982)
18 175.43073854176043 0.313 -7.991 -0.011 tensor(-0.3932)
19 629.9729645081184 0.43 -74.664 -0.011 tensor(-3.7874)
20 677.0114114796888 0.432 -195.521 -0.011 tensor(2.7560)
21 761.6641232024219 0.612 -172.702 -0.01 tensor(-3.5137)
22 51.85777510243115 0.002 -75.005 -0.009 tensor(1.1033)
23 129.4717997995558 0.059 -2.613 -0.006 tensor(0.8854)
24 -0.02642582698604201 0.496 -12.185 -0.005 tensor(-2.2238)
25 13.383232154472125 0.289 -8.885 -0.005 tensor(-0.0805)
26 1025.832330203383 0.091 -416.754 -0.003 tensor(-3.9231)
27 241.19102113435642 0.409 -9.932 -0.005 tensor(-1.1717)
28 495.8002954422322 0.67 -3.903 -0.007 tensor(-0.8097)
29 459.25641523599006 0.104 -39.091 -0.008 tensor(-2.4256)
30 163.11424166122458 0.052 -53.461 -0.005 tensor(0.0193)
31 890.8298163879148 0.196 -250.365 -0.005 tensor(3.6372)
32 687.5091550271312 0.273 -50.031 -0.008 tensor(-0.3284)
33 476.68059397284594 0.059 -10.259 -0.012 tensor(1.0488)
34 15.235348373685241 0.714 -55.585 -0.006 tensor(1.3159)
35 166.0041117414779 0.1 -12.385 -0.012 tensor(1.9316)
36 57.39893216465579 0.336 -199.481 -0.001 tensor(0.4273)
37 54.31863375833231 0.161 -126.32 -0.01 tensor(-0.0548)
38 290.4726292454143 0.054 -7.962 -0.004 tensor(0.3389)
39 785.0919750698675 0.644 -44.061 -0.011 tensor(0.5506)
40 237.74210164509395 0.295 -8.97 -0.014 tensor(-0.4764)

41 268.95426187047815 0.507 -16.558 -0.012 tensor(1.3433)
42 487.8267744723853 0.008 -210.149 -0.012 tensor(2.3756)
43 318.9842438549583 0.571 -65.412 -0.009 tensor(-1.7550)
44 255.20270091769325 0.619 -1.097 -0.006 tensor(2.4243)
45 1068.4166216480808 0.089 -43.115 -0.01 tensor(2.7262)
46 1304.5769425143862 0.394 -155.166 -0.007 tensor(2.6229)
47 1363.0834599194134 0.029 -172.62 -0.007 tensor(1.0068)
48 98.25962596718867 0.599 -117.681 -0.009 tensor(2.4438)
49 619.0278456284287 0.409 -135.168 -0.007 tensor(0.7982)
50 142.32158729272135 0.037 -108.997 -0.005 tensor(1.7013)
51 1372.704231101622 0.407 -53.728 -0.01 tensor(4.0311)
52 245.03871797617236 0.056 -142.909 -0.011 tensor(2.9488)
53 176.31123214996256 0.255 -98.698 -0.011 tensor(-0.1991)
54 664.8386852804911 0.101 -137.317 -0.007 tensor(3.4954)
55 275.7388012124215 0.164 -18.977 -0.008 tensor(1.8315)
56 206.64002364436828 0.192 -9.308 -0.011 tensor(1.6398)
57 597.04731875583 0.172 -168.937 -0.012 tensor(4.1727)
58 148.20536420483404 0.012 -50.854 -0.005 tensor(1.6518)
59 314.18533855092494 0.22 -114.411 -0.008 tensor(1.1577)
60 36.9797558279688 0.093 -154.585 0.0 tensor(-1.0551)
61 26.30578488635295 0.006 -112.967 -0.009 tensor(0.3481)
62 121.90980928988532 0.052 -25.044 -0.008 tensor(2.6610)
63 32.385557301702455 0.52 -86.997 -0.011 tensor(2.1189)
64 64.56375528854494 0.011 -175.794 -0.008 tensor(3.5868)
65 94.04926171295213 0.211 -30.255 -0.006 tensor(3.0540)
66 189.45998468050806 0.143 -203.265 -0.008 tensor(0.9644)
67 831.5022920779838 0.446 -178.027 -0.004 tensor(2.0420)
68 23.06384660504682 0.607 -55.995 -0.007 tensor(1.1688)
69 238.81739563786925 0.709 -56.565 -0.007 tensor(1.8745)
70 137.49178189249307 0.052 -56.316 -0.01 tensor(4.0546)
71 121.09380364076605 0.093 -15.896 -0.01 tensor(0.8013)
72 60.76240265144747 0.003 -92.686 -0.011 tensor(1.2484)
73 81.5679106228256 0.34 -433162.75 0.0 tensor(2.3132)
74 79.37863628290947 0.005 -25.175 -0.011 tensor(4.7824)
75 90.91023629882238 0.114 -111.654 -0.011 tensor(2.4300)
76 789.2849235161937 0.182 -164.773 -0.01 tensor(2.8614)
77 153.4163115361706 0.079 -24.361 -0.008 tensor(4.2672)
78 83.89902928453215 0.107 -909.555 -0.011 tensor(7.8654)
79 436.2602958824043 0.387 -53.562 -0.008 tensor(3.3308)
80 254.29317911863043 0.109 -36.269 -0.007 tensor(1.1983)
81 502.160937740888 0.286 -13.546 -0.009 tensor(2.5342)
82 5.137291160800263 0.0 -205442.375 0.0 tensor(2.5908)
83 329.0676437849281 0.012 -48.858 -0.008 tensor(2.1227)
84 37.80386277988854 0.687 -228.766 -0.008 tensor(4.0760)
85 374.4928838892283 0.106 -85.44 -0.011 tensor(3.7524)
86 257.67327738923586 0.387 -7.787 -0.009 tensor(1.9751)
87 192.69468188151802 0.068 -10.825 -0.005 tensor(1.5098)
88 323.0311004160594 0.091 -317.805 -0.011 tensor(5.3461)
89 522.4669121606892 0.119 -14.533 -0.006 tensor(2.0138)
90 765.7004803146465 0.474 -36.103 -0.011 tensor(1.5218)
91 1012.2400445188146 0.634 -104.272 -0.01 tensor(2.5032)
92 291.7112658269882 0.389 -103.218 -0.01 tensor(0.1979)
93 1131.9472914596295 0.067 -62.673 0.0 tensor(3.9293)
94 324.13287074138424 0.134 -107.296 -0.008 tensor(0.1317)
95 381.46248877397966 0.421 -17.531 -0.005 tensor(2.1943)
96 1.518770604609017 0.165 -24.396 -0.008 tensor(1.7219)
97 94.03381608456309 0.065 -236.081 -0.011 tensor(1.0432)
98 30.906518962509054 0.353 -19.025 -0.009 tensor(3.6554)
99 8.987099134023993 0.122 -31.796 -0.006 tensor(-0.6308)
100 0.2858243516588317 0.509 -74.24 -0.009 tensor(1.5990)
101 377.3542164221644 0.138 -45.776 -0.008 tensor(3.5238)
102 956.1204115884354 0.214 -190.796 -0.008 tensor(1.3475)
103 682.1938819047411 0.546 -12.233 -0.008 tensor(1.9217)
104 283.96045602832623 0.016 -45.865 -0.009 tensor(2.7917)
105 317.4455226243575 0.33 -56.62 -0.01 tensor(3.9049)
106 1030.715369334832 0.121 -133.139 -0.01 tensor(1.3780)
107 1428.5147253122536 0.572 -265.899 -0.007 tensor(3.8559)
108 294.9035033238524 0.245 -211.072 0.0 tensor(2.6960)
109 56.21881106546917 0.172 -223.672 -0.01 tensor(3.8814)
110 188.37231267518052 0.234 -187.954 -0.01 tensor(1.8265)
111 211.45358776859098 0.022 -101.439 -0.006 tensor(3.8029)
112 351.28219728570855 0.154 -38.389 -0.007 tensor(3.1735)
113 1559.9708180119055 0.161 -430.57 -0.005 tensor(4.7799)
114 81.78629841791462 0.539 -191.664 -0.005 tensor(3.8817)
115 4.82515111003886 0.356 -117.644 -0.008 tensor(1.9350)
116 237.02255321837538 0.266 -107.73 -0.01 tensor(3.7447)
117 391.4519803345968 0.612 -257.784 -0.011 tensor(5.8808)
118 36.81566569782737 0.3 -27.469 -0.006 tensor(2.7218)
